{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-terrier\n",
      "  Cloning https://github.com/terrier-org/pyterrier.git to c:\\users\\mikee\\appdata\\local\\temp\\pip-install-6k6cacxz\\python-terrier_d709c806cf5f4e29b52a7055b0a261c2\n",
      "  Resolved https://github.com/terrier-org/pyterrier.git to commit c510ac784e7626f19ad5a6bad50e475d84fbd129\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting wget\n",
      "  Using cached wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\mikee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-terrier) (4.64.1)\n",
      "Collecting pyjnius>=1.4.2\n",
      "  Using cached pyjnius-1.4.2-cp310-cp310-win_amd64.whl (197 kB)\n",
      "Collecting matchpy\n",
      "  Using cached matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deprecation\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting chest\n",
      "  Using cached chest-0.2.3.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\mikee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-terrier) (1.2.0)\n",
      "Collecting nptyping==1.4.4\n",
      "  Using cached nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Collecting more_itertools\n",
      "  Using cached more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "Collecting ir_datasets>=0.3.2\n",
      "  Using cached ir_datasets-0.5.4-py3-none-any.whl (311 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.13.2-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "Collecting ir_measures>=0.3.1\n",
      "  Using cached ir_measures-0.3.1.tar.gz (46 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting pytrec_eval_terrier>=0.5.3\n",
      "  Using cached pytrec_eval_terrier-0.5.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "Collecting typish>=1.7.0\n",
      "  Using cached typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "Collecting beautifulsoup4>=4.4.1\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5\n",
      "  Using cached warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting unlzw3>=0.2.1\n",
      "  Using cached unlzw3-0.2.1-py3-none-any.whl\n",
      "Collecting lz4>=3.1.1\n",
      "  Using cached lz4-4.0.2-cp310-cp310-win_amd64.whl (98 kB)\n",
      "Collecting warc3-wet>=0.2.3\n",
      "  Using cached warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
      "Collecting zlib-state>=0.1.3\n",
      "  Using cached zlib_state-0.1.5-cp310-cp310-win_amd64.whl (12 kB)\n",
      "Collecting ijson>=3.1.3\n",
      "  Using cached ijson-3.1.4.tar.gz (56 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting trec-car-tools>=2.5.4\n",
      "  Using cached trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Collecting lxml>=4.5.2\n",
      "  Using cached lxml-4.9.1-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting pyautocorpus>=0.1.1\n",
      "  Using cached pyautocorpus-0.1.9-cp310-cp310-win_amd64.whl (7.1 kB)\n",
      "Collecting cwl-eval>=1.0.10\n",
      "  Using cached cwl-eval-1.0.12.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\mikee\\appdata\\roaming\\python\\python310\\site-packages (from pyjnius>=1.4.2->python-terrier) (1.16.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mikee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->python-terrier) (0.4.5)\n",
      "Collecting heapdict\n",
      "  Using cached HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mikee\\appdata\\roaming\\python\\python310\\site-packages (from deprecation->python-terrier) (21.3)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting multiset<3.0,>=2.0\n",
      "  Using cached multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mikee\\appdata\\roaming\\python\\python310\\site-packages (from pandas->python-terrier) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.5-py2.py3-none-any.whl (500 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mikee\\appdata\\roaming\\python\\python310\\site-packages (from packaging->deprecation->python-terrier) (3.0.9)\n",
      "Collecting cbor>=1.0.0\n",
      "  Using cached cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Using legacy 'setup.py install' for python-terrier, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for ir_measures, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for chest, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wget, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for cwl-eval, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for ijson, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for warc3-wet-clueweb09, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for cbor, since package 'wheel' is not installed.\n",
      "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, typish, pytz, multiset, ijson, heapdict, cbor, zlib-state, urllib3, unlzw3, threadpoolctl, soupsieve, pyyaml, pytrec_eval_terrier, pyjnius, pyautocorpus, numpy, more_itertools, matchpy, MarkupSafe, lz4, lxml, idna, dill, chest, charset-normalizer, certifi, trec-car-tools, scipy, requests, patsy, pandas, nptyping, jinja2, deprecation, cwl-eval, beautifulsoup4, statsmodels, scikit-learn, ir_measures, ir_datasets, sklearn, python-terrier\n",
      "  Running setup.py install for wget: started\n",
      "  Running setup.py install for wget: finished with status 'done'\n",
      "  Running setup.py install for warc3-wet-clueweb09: started\n",
      "  Running setup.py install for warc3-wet-clueweb09: finished with status 'done'\n",
      "  Running setup.py install for ijson: started\n",
      "  Running setup.py install for ijson: finished with status 'done'\n",
      "  Running setup.py install for cbor: started\n",
      "  Running setup.py install for cbor: finished with status 'done'\n",
      "  Running setup.py install for chest: started\n",
      "  Running setup.py install for chest: finished with status 'done'\n",
      "  Running setup.py install for cwl-eval: started\n",
      "  Running setup.py install for cwl-eval: finished with status 'done'\n",
      "  Running setup.py install for ir_measures: started\n",
      "  Running setup.py install for ir_measures: finished with status 'done'\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "  Running setup.py install for python-terrier: started\n",
      "  Running setup.py install for python-terrier: finished with status 'done'\n",
      "Successfully installed MarkupSafe-2.1.1 beautifulsoup4-4.11.1 cbor-1.0.0 certifi-2022.9.24 charset-normalizer-2.1.1 chest-0.2.3 cwl-eval-1.0.12 deprecation-2.1.0 dill-0.3.6 heapdict-1.0.1 idna-3.4 ijson-3.1.4 ir_datasets-0.5.4 ir_measures-0.3.1 jinja2-3.1.2 lxml-4.9.1 lz4-4.0.2 matchpy-0.5.5 more_itertools-9.0.0 multiset-2.1.1 nptyping-1.4.4 numpy-1.23.4 pandas-1.5.1 patsy-0.5.3 pyautocorpus-0.1.9 pyjnius-1.4.2 python-terrier-0.8.1 pytrec_eval_terrier-0.5.5 pytz-2022.5 pyyaml-6.0 requests-2.28.1 scikit-learn-1.1.3 scipy-1.9.3 sklearn-0.0 soupsieve-2.3.2.post1 statsmodels-0.13.2 threadpoolctl-3.1.0 trec-car-tools-2.6 typish-1.9.3 unlzw3-0.2.1 urllib3-1.26.12 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/terrier-org/pyterrier.git 'C:\\Users\\mikee\\AppData\\Local\\Temp\\pip-install-6k6cacxz\\python-terrier_d709c806cf5f4e29b52a7055b0a261c2'\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\mikee\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\mikee\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script ir_datasets.exe is installed in 'c:\\Users\\mikee\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade git+https://github.com/terrier-org/pyterrier.git#egg=python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from post_parser_record import PostParserRecord\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus.reader.tagged import word_tokenize\n",
    "import re, string\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will take in a string , clean it up, and return it\n",
    "def clean_text(text):\n",
    "    token_words = re.sub(\"<.*?>|\\\\n|&quot;\", \" \", text.lower())\n",
    "    token_words = word_tokenize(token_words.translate(str.maketrans('', '', string.punctuation)))\n",
    "    token_words = [word for word in token_words if word not in stop_words]\n",
    "    return \" \".join(token_words)\n",
    "\n",
    "# turn the xml into a dataframe\n",
    "df = pd.read_xml(\"../Posts_Small.xml\")\n",
    "\n",
    "# lambda function for converting nonetype to empty string\n",
    "conv = lambda i : i or ''\n",
    "# print(conv(df.iloc[4].Title))\n",
    "# print(df.iloc[4].Title + \" \" + df.iloc[4].Body)\n",
    "\n",
    "# make a text column with title + body and get rid of unnecessary columns\n",
    "df['text'] = + df['Body'].apply(conv) + \" \" + df['Title'].apply(conv)\n",
    "df = df.drop(columns=['PostTypeId', 'AcceptedAnswerId', 'CreationDate', 'Score',\n",
    "       'ViewCount', 'Body', 'OwnerUserId', 'LastEditorUserId', 'LastEditDate',\n",
    "       'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'CommentCount',\n",
    "       'FavoriteCount', 'ContentLicense', 'LastEditorDisplayName',\n",
    "       'ClosedDate', 'CommunityOwnedDate', 'ParentId'])\n",
    "\n",
    "# set the text column to type string\n",
    "df = df.astype({'text': str})\n",
    "\n",
    "# apply the clean text function to text\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# rename id to docno\n",
    "df = df.rename(columns={'Id': 'docno'})\n",
    "\n",
    "# add url\n",
    "df['url'] = \"url\" + df['docno'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:41:52.310 [main] ERROR org.terrier.structures.Index - Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS_470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to\n"
     ]
    },
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS_470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to java.lang.IllegalArgumentException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pd_indexer \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mDFIndexer(\u001b[39m\"\u001b[39m\u001b[39m./pd_index\u001b[39m\u001b[39m\"\u001b[39m, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m indexref \u001b[39m=\u001b[39m pd_indexer\u001b[39m.\u001b[39;49mindex(df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], df)\n",
      "File \u001b[1;32mc:\\Users\\mikee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyterrier\\index.py:511\u001b[0m, in \u001b[0;36mDFIndexer.index\u001b[1;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     javaDocCollection \u001b[39m=\u001b[39m TQDMSizeCollection(javaDocCollection, \u001b[39mlen\u001b[39m(text)) \n\u001b[0;32m    510\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreateIndexer()\n\u001b[1;32m--> 511\u001b[0m index\u001b[39m.\u001b[39;49mindex(autoclass(\u001b[39m\"\u001b[39;49m\u001b[39morg.terrier.python.PTUtils\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmakeCollection(javaDocCollection))\n\u001b[0;32m    512\u001b[0m \u001b[39mglobal\u001b[39;00m lastdoc\n\u001b[0;32m    513\u001b[0m lastdoc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mjnius\\jnius_export_class.pxi:885\u001b[0m, in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mjnius\\jnius_export_class.pxi:982\u001b[0m, in \u001b[0;36mjnius.JavaMethod.call_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mjnius\\jnius_utils.pxi:91\u001b[0m, in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS_470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to java.lang.IllegalArgumentException"
     ]
    }
   ],
   "source": [
    "pd_indexer = pt.DFIndexer(\"./pd_index\", overwrite=True)\n",
    "indexref = pd_indexer.index(df['text'], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:33:48.570 [main] ERROR org.terrier.structures.Index - Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS 470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to\n"
     ]
    },
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS 470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to java.lang.IllegalArgumentException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [51], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# index the text, record the docnos as metadata\u001b[39;00m\n\u001b[0;32m     14\u001b[0m pd_indexer \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mDFIndexer(\u001b[39m\"\u001b[39m\u001b[39m./pd_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m indexref \u001b[39m=\u001b[39m pd_indexer\u001b[39m.\u001b[39;49mindex(df[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], df[\u001b[39m\"\u001b[39;49m\u001b[39mdocno\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\mikee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyterrier\\index.py:511\u001b[0m, in \u001b[0;36mDFIndexer.index\u001b[1;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     javaDocCollection \u001b[39m=\u001b[39m TQDMSizeCollection(javaDocCollection, \u001b[39mlen\u001b[39m(text)) \n\u001b[0;32m    510\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreateIndexer()\n\u001b[1;32m--> 511\u001b[0m index\u001b[39m.\u001b[39;49mindex(autoclass(\u001b[39m\"\u001b[39;49m\u001b[39morg.terrier.python.PTUtils\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmakeCollection(javaDocCollection))\n\u001b[0;32m    512\u001b[0m \u001b[39mglobal\u001b[39;00m lastdoc\n\u001b[0;32m    513\u001b[0m lastdoc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mjnius\\jnius_export_class.pxi:885\u001b[0m, in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mjnius\\jnius_export_class.pxi:982\u001b[0m, in \u001b[0;36mjnius.JavaMethod.call_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mjnius\\jnius_utils.pxi:91\u001b[0m, in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: Cannot create new index: path c:\\Users\\mikee\\Desktop\\School\\Fall_2022\\COS 470\\project\\part2\\IRCourse-Project2-TiffanyHoeung-MikeBelley\\.\\var\\./pd_index does not exist, or cannot be written to java.lang.IllegalArgumentException"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'docno':\n",
    "    ['1', '2', '3'],\n",
    "    'url':\n",
    "    ['url1', 'url2', 'url3'],\n",
    "    'text':\n",
    "    ['He ran out of money, so he had to stop playing',\n",
    "    'The waves were crashing on the shore; it was a',\n",
    "    'The body may perhaps compensates for the loss']\n",
    "})\n",
    "\n",
    "# index the text, record the docnos as metadata\n",
    "pd_indexer = pt.DFIndexer(\"./pd_index\")\n",
    "indexref = pd_indexer.index(df[\"text\"], df[\"docno\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df4d5b2805f2694e1d5ca6f97a46794d37e88743b50251a393ec91df99044f5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
